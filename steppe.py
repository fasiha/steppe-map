# -*- encoding: utf-8 -*-

from pyproj import Proj
import numpy as np
import numpy.linalg as la
import scipy.linalg as scila

p = Proj(proj='moll', lon_0=-90.0)
lon, lat = (-120.108, 34.36116666)
x, y = p(lon, lat)
lon1, lat1 = p(x, y, inverse=True)

def loaddata(fname="gcp.txt"):
    """Load QGIS-style georeference control points (GCP) file.

    The first line will be skipped, and the rest of the lines are assumed to be
    comma-separated numbers.

    Four vectors will be returned:
    - lon, degrees,
    - lat, degrees,
    - x, pixel, and
    - y (pixel).

    """
    arr = np.genfromtxt(fname, skip_header=1, delimiter=',')[:,:4]
    lon, lat, x, y = arr.T
    return (lon, lat, x, y)

def L2_norm_error(true, estimated):
    """Compute the normalized L^2 error between two values.

    Compute the L^2 error between two numeric inputs, one of them considered
    "true" (say, x) and the other an "approximation" (say, y), and normalize
    this error using the L^2 norm of x:

    sqrt(|x_1 - y_1|^2 + .. + |x_N - y_N|^2) / sqrt(|x_1|^2 + .. + |x_N|^2).

    The summation is taken over all elements of the inputs: arrays are
    effectively raveled (rasterized).

    To ensure that two numerics that should be "equal" are indeed equal,
    verifying that this function's' output is near machine precision (see
    `numpy.spacing`).

    """
    L2 = lambda x: np.sqrt(np.sum(np.abs(x)**2))
    return L2(true - estimated) / L2(true)

def remove_affine(p, q, q_factor=None, skip_factorization=False):
    """Removes an (unknown) affine transform between two matrixes.

    Given two arrays of the same size, `p` and `q`, finds a matrix `A` and
    column vector `t` such that

    `p \approx A * q + t`

    in the least-squares sense, and then computes `qnew = A * q + t`. (Notation:
    `matrix + vector` implies the vector is added to each column of the matrix.)

    NB: `p` and the returned `qnew` will be equal if and only if `p` is
    generated from `q` via an affine transform (no noise).

    Returns `(qnew, q_factor)`, the latter a matrix factorization that can
    greatly speeds up subsequent calls to remove_affine *with the same `q`*. If
    your `q` stays the same for multiple calls, cache `q_factor` and pass it in
    as a keyword argument; `q_factor` won't change from call to call. However,
    if your `q` change from call to call, ignore `q_factor` and pass in
    `skip_factorization=False` to avoid even calculating it.

    NB2: the default `q_factor=None` will trigger computation of the
    factorization unless `skip_factorization=False`. Non-`None` `q_factor` will
    be trusted: no checks will be performed to make sure the given `q_factor` is
    indeed generated by the `q` you pass in. (Example: for `q.shape` of (2, 22),
    the speedup from using `q_factor` is 1.4x with skip_factorization=False, and
    1.3x the case with skip_factorization=True, on a 2009 Mac Book Pro.)

    Implements the algorithm described in H. Spath, "Fitting affine and
    orthogonal transformations between two sets of points" in *Mathematical
    Communications*, vol. 9 (2004), pp. 27--34. http://hrcak.srce.hr/file/1425â€Ž

    """

    qaug = np.vstack([q, np.ones_like(q[0,:])])
    if q_factor is None:
        Q = np.dot(qaug, qaug.T)

        if skip_factorization:
            sol = la.lstsq(Q, np.dot(qaug, p.T))[0]
            q_factor = None

        else:
            q_factor = scila.cho_factor(Q)
            sol = scila.cho_solve(q_factor, np.dot(qaug, p.T))

    else:
        sol = scila.cho_solve(q_factor, np.dot(qaug, p.T))

    # sol.shape is (n+1, n), for n=p.shape[0]
    Ahat = sol[:-1,:].T # top square matrix of sol, transposed
    that = sol[-1:,:].T # bottom row vector of sol, transposed
    qnew = np.dot(Ahat, q) + that
    return (qnew, q_factor)


def remove_linear(x, xp):
    """Find and remove a linear translation between two vectors.

    Given some "good" data in vector x, and an approximation in xp ("p" for
    "prime"), first find the best-fit (in the least-squares sense) slope, m, and
    intercept, b, of

    x = m * xp + b,

    and then return (m*xp + b).

    In linear algebra terms, in compact Matlab/Octave notation, this is (where
    the `(:)` operation is equivalent to `.ravel()` and `\` is the left matrix
    divide):

    ```
    A = [xp(:), ones(size(xp(:)))]
    return A * (A \ x(:))
    ```

    That last line can be replaced with `return A * pinv(A' * A) * A' * x(:)`
    where `'` indicates transpose. Note the hat matrix (or projection matrix) in
    this expression: we're just doing ordinary least squares (OLS).

    This is useful when x and xp are in different units (Celcius versus
    Farenheit, or pixel locations in different images with different origins).
    This function will try to convert xp into the units of x, assuming the units
    are linearly related.

    If the inputs are arrays, the function is called recursively on each axis,
    so that the above operation is done only to vectors. For example, if you
    pass in two 2xN arrays, the output will apply the above operation to the
    first 1xN vector and then the second, finding different slopes/intercepts
    for each row.

    NB: the order of arguments to this function is important! If you have some
    good data x and some scaled approximation xp, you would only expect coherent
    results if you compared the error between x and `remove_linear(x, xp)`.
    Flipping the arguments to remove_linear will give you the wrong answer.

    """
    if x.shape != xp.shape:
        raise ValueError("inputs are not same dimension")

    if x.ndim == 1:
        A = np.vstack([xp, np.ones_like(xp)]).T # Data matrix for least-squares
        slope_intercept = la.lstsq(A, x)[0]     # lstsq returns other stuff too
        newxp = np.dot(A, slope_intercept)
        return newxp
    else:
        return np.hstack(map(remove_linear, x, xp)).reshape(xp.shape)

def grid1dsearch(lon, lat, x, y, proj='moll', plot=True):
    xy = np.vstack([x, y])
    grid = np.arange(-180, 180.0, 1.0)
    errs = np.empty_like(grid)
    for (idx, l) in enumerate(grid):
        p = Proj(proj=proj, lon_0=l)
        xout, yout = p(lon, lat)
        #xout, yout = remove_linear(xy, np.vstack([xout, yout]))
        xout, yout = remove_affine(xy, np.vstack([xout, yout]))[0]
        errs[idx] = L2_norm_error(np.vstack([x,y]), np.vstack([xout, yout]))
    if plot:
        try:
            import pylab as plt
            plt.ion()
            plt.figure()
            plt.plot(grid, errs)
            title = "%s projection, min=%g at %g degrees" % (proj, np.min(errs),
                                                        grid[np.argmin(errs)])
            plt.title(title)
        except ImportError:
            print "Couldn't plot!"
    return (grid, errs, xout, yout)

def proj1d(recompute=True):
    """List of 1D-only projections from [1]. Returns list of strings.

    Ones here but not in pseudocylindrical list: ortho

    In pseudocylindrical but >1D so omitted here: loxim.

    DON'T work with pyproj but are in [1]: hataea, quau, dense, parab.

    [1] ftp://ftp.remotesensing.org/proj/OF90-284.pdf

    """

    if recompute is False:
        return 'sinu,moll,robin,eck1,eck2,eck3,eck4,eck5,eck6,goode,mbtfpp,mbtfpq,mbtfps,putp2,putp5,wink1,boggs,collg,ortho'.split(',')

    pall = 'sinu,moll,robin,eck1,eck2,eck3,eck4,eck5,eck6,goode,hataea,mbtfpp,mbtfpq,mbtfps,putp2,putp5,quau,wink1,boggs,collg,dense,parab,ortho'.split(',')

    (lon, lat, x, y) = loaddata()
    p = []
    for proj in pall:
        try:
            (grid, errs, _, _) = grid1dsearch(lon, lat, x, y,
                                              proj=proj, plot=False)
            print "%s: min=%g @ %g degrees" % (proj, np.min(errs),
                                               grid[np.argmin(errs)])
            p.append(proj)
        except:
            print "%s didn't work" % (proj,)
    print p.join(',')
    return p

def image_show(x, y, xout, yout, imname="small.gif"):
    """Load and show an image with control points and estimates.

    Given control points in vectors x and y containing pixels, as well as
    estimates obtained (using some projection), plot both values so they can be
    visually compared.

    """
    import pylab as plt
    plt.ion()
    im = plt.imread(imname)

    fig = plt.figure()
    ax = fig.add_subplot(111)

    ax.imshow(im)

    annot_helper = lambda x, y, **kwargs: ax.annotate("%g,%g"%(x, y),
                                            xy=(x, y), xytext=(x+10, y+10),
                                            size=15,
                                            arrowprops=dict(facecolor='black',
                                                            shrink=0.05),
                                            **kwargs)
    [annot_helper(xi, yi, color='g') for xi,yi in zip(x, y)]
    [annot_helper(xi, yi, color='r') for xi,yi in zip(xout, yout)]

    plt.title("Green: control points. Red: fit points.")



if __name__ == "__main__":
    (lon, lat, x, y) = loaddata()
    (grid, errs, xout, yout) = grid1dsearch(lon, lat, x, y, 'moll', True)
    image_show(x,-y,xout,-yout)
