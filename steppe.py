# -*- encoding: utf-8 -*-

from pyproj import Proj
import numpy as np
import numpy.linalg as la
import scipy.linalg as scila
import scipy.optimize as opt


def loaddata(fname="gcp.txt"):
    """Load QGIS-style georeference control points (GCP) file.

    The first line will be skipped, and the rest of the lines are assumed to be
    comma-separated numbers.

    Four vectors will be returned:
    - lon, degrees,
    - lat, degrees,
    - x, pixel, and
    - y (pixel).

    """
    arr = np.genfromtxt(fname, skip_header=1, delimiter=',')[:, :4]
    lon, lat, x, y = arr.T
    return (lon, lat, x, y)


def L2_norm_error(true, estimated):
    """Compute the normalized L^2 error between two values.

    Compute the L^2 error between two numeric inputs, one of them considered
    "true" (say, x) and the other an "approximation" (say, y), and normalize
    this error using the L^2 norm of x:

    sqrt(|x_1 - y_1|^2 + .. + |x_N - y_N|^2) / sqrt(|x_1|^2 + .. + |x_N|^2).

    The summation is taken over all elements of the inputs: arrays are
    effectively raveled (rasterized).

    To ensure that two numerics that should be "equal" are indeed equal, verify
    that this function's output is near machine precision (see `numpy.spacing`).

    """
    L2 = lambda x: np.sqrt(np.sum(np.abs(x)**2))
    return L2(true - estimated) / L2(true)


def remove_affine(p, q, q_factor=None, skip_factorization=False):
    """Removes an (unknown) affine transform between two matrixes.

    Given two arrays of the same size, `p` and `q`, finds a matrix `A` and
    column vector `t` such that

    `p = A * q + t`

    in the least-squares sense, and then computes `qnew = A * q + t`. (Notation:
    `matrix + vector` implies the vector is added to each column of the matrix.)

    NB: `p` and the returned `qnew` will be equal if and only if `p` is
    generated from `q` via an affine transform (no noise).

    Returns `(qnew, q_factor, Ahat, that)`. `q_factor` is a matrix factorization
    that can greatly speed up subsequent calls to remove_affine *with the same
    `q`*. If your `q` stays the same for multiple calls, cache `q_factor` and
    pass it in as a keyword argument; `q_factor` won't change from call to call.
    However, if your `q` change from call to call, ignore `q_factor` and pass in
    `skip_factorization=False` to avoid even calculating it. `Ahat` and `that`
    are the estimated values of `A` and `t`.

    NB2: the default `q_factor=None` will trigger computation of the
    factorization unless `skip_factorization=False`. Non-`None` `q_factor` will
    be trusted: no checks will be performed to make sure the given `q_factor` is
    indeed generated by the `q` you pass in. (Example: for `q.shape` of (2, 22),
    the speedup from using `q_factor` is 1.4x with skip_factorization=False, and
    1.3x the case with skip_factorization=True, on a 2009 Mac Book Pro.)

    Implements the algorithm described in H. Spath, "Fitting affine and
    orthogonal transformations between two sets of points" in *Mathematical
    Communications*, vol. 9 (2004), pp. 27--34. http://hrcak.srce.hr/file/1425

    """

    qaug = np.vstack([q, np.ones_like(q[0, :])])
    if q_factor is None:
        Q = np.dot(qaug, qaug.T)

        if skip_factorization:
            sol = la.lstsq(Q, np.dot(qaug, p.T))[0]
            q_factor = None

        else:
            q_factor = scila.cho_factor(Q)
            sol = scila.cho_solve(q_factor, np.dot(qaug, p.T))

    else:
        sol = scila.cho_solve(q_factor, np.dot(qaug, p.T))

    # sol.shape is (n+1, n), for n=p.shape[0]
    Ahat = sol[:-1, :].T  # top square matrix of sol, transposed
    that = sol[-1:, :].T  # bottom row vector of sol, transposed
    qnew = np.dot(Ahat, q) + that
    return (qnew, q_factor, Ahat, that)


def remove_linear(x, xp):
    """Find and remove a linear translation between two vectors.

    Given some "good" data in vector x, and an approximation in xp ("p" for
    "prime"), first find the best-fit (in the least-squares sense) slope, m, and
    intercept, b, of

    x = m * xp + b,

    and then return (m*xp + b).

    In linear algebra terms, in compact Matlab/Octave notation, this is (where
    the `(:)` operation is equivalent to `.ravel()` and `\` is the left matrix
    divide):

    ```
    A = [xp(:), ones(size(xp(:)))]
    return A * (A \ x(:))
    ```

    That last line can be replaced with `return A * pinv(A' * A) * A' * x(:)`
    where `'` indicates transpose. Note the hat matrix (or projection matrix) in
    this expression: we're just doing ordinary least squares (OLS).

    This is useful when x and xp are in different units (Celcius versus
    Farenheit, or pixel locations in different images with different origins).
    This function will try to convert xp into the units of x, assuming the units
    are linearly related.

    If the inputs are arrays, the function is called recursively on each axis,
    so that the above operation is done only to vectors. For example, if you
    pass in two 2xN arrays, the output will apply the above operation to the
    first 1xN vector and then the second, finding different slopes/intercepts
    for each row.

    NB: the order of arguments to this function is important! If you have some
    good data x and some scaled approximation xp, you would only expect coherent
    results if you compared the error between x and `remove_linear(x, xp)`.
    Flipping the arguments to remove_linear will give you the wrong answer.

    """
    if x.shape != xp.shape:
        raise ValueError("inputs are not same dimension")

    if x.ndim == 1:
        A = np.vstack([xp, np.ones_like(xp)]).T  # Data matrix for least-squares
        slope_intercept = la.lstsq(A, x)[0]  # lstsq returns other stuff too
        newxp = np.dot(A, slope_intercept)
        return newxp
    else:
        return np.hstack(map(remove_linear, x, xp)).reshape(xp.shape)


def search(lon, lat, x, y, proj, vec2dictfunc, init):
    xy = np.vstack([x, y])

    def func(inputvec):
        p = Proj(proj=proj, **vec2dictfunc(inputvec))
        xout, yout = p(lon, lat)
        xout, yout = remove_affine(xy, np.vstack([xout, yout]))[0]
        return L2_norm_error(np.vstack([x, y]), np.vstack([xout, yout]))

    sols = []
    sols.append(opt.fmin(func, init, full_output=True, disp=False))
    sols.append(opt.fmin_powell(func, init, full_output=True, disp=False))
    sols.append(opt.fmin_bfgs(func, init, full_output=True, disp=False))

    (idx_x, idx_fx) = (0, 1)
    best = np.argmin(map(lambda x: x[idx_fx], sols))
    return sols[best]


def make_vector2dictfunc(string, delimiter=',', initvec=None):
    substrings = string.split(delimiter)
    if initvec and (len(initvec) != len(substrings)):
        print("string=[{}] not split {}-ways".format(string, len(initvec)))
        return None
    return lambda x: dict(zip(substrings, np.atleast_1d(x)))


def grid1dsearch(lon, lat, x, y, proj='moll', plot=True):
    xy = np.vstack([x, y])
    grid = np.arange(-180, 180.0, .25)
    errs = np.empty_like(grid)
    for (idx, l) in enumerate(grid):
        p = Proj(proj=proj, lon_0=l)
        xout, yout = p(lon, lat)
        #xout, yout = remove_linear(xy, np.vstack([xout, yout]))
        xout, yout = remove_affine(xy, np.vstack([xout, yout]))[0]
        errs[idx] = L2_norm_error(np.vstack([x, y]), np.vstack([xout, yout]))

    if plot:
        try:
            import pylab as plt
            plt.ion()
            plt.figure()
            plt.plot(grid, errs)
            title = "%s projection, min=%g at %g degrees" % (proj, np.min(errs),
                                                             grid[np.argmin(errs)])
            plt.title(title)
        except ImportError:
            print("Couldn't plot!")

    bestidx = np.argmin(errs)
    p = Proj(proj=proj, lon_0=grid[bestidx])
    xout, yout = p(lon, lat)
    xout, yout = remove_affine(xy, np.vstack([xout, yout]))[0]

    return (grid, errs, xout, yout)


def proj1d(recompute=True):
    """List of 1D-only projections from [1]. Returns list of strings.

    Ones here but not in pseudocylindrical list: ortho

    In pseudocylindrical but >1D so omitted here: loxim.

    DON'T work with pyproj but are in [1]: hataea, quau, dense, parab.

    [1] ftp://ftp.remotesensing.org/proj/OF90-284.pdf

    """

    if recompute is False:
        return 'sinu,moll,robin,eck1,eck2,eck3,eck4,eck5,eck6,goode,mbtfpp,mbtfpq,mbtfps,putp2,putp5,wink1,boggs,collg,ortho'.split(
            ',')

    pall = 'sinu,moll,robin,eck1,eck2,eck3,eck4,eck5,eck6,goode,hataea,mbtfpp,mbtfpq,mbtfps,putp2,putp5,quau,wink1,boggs,collg,dense,parab,ortho'.split(
        ',')

    (lon, lat, x, y) = loaddata()
    p = []
    for proj in pall:
        # try:
        (grid, errs, _, _) = grid1dsearch(lon, lat, x, y, proj=proj, plot=False)
        print("{}: min={} @ {} degrees".format(proj, np.min(errs), grid[np.argmin(errs)]))
        p.append(proj)
        # except:
        #     print ("{} didn't work".format(proj)
    print(",".join(p))
    return p


def loadshapefile():
    import os.path
    import shapefile
    import pyproj

    # countriespath = os.path.join('ne', 'ne_10m_admin_0_countries', 'ne_10m_admin_0_countries')
    coastpath = os.path.join('ne', 'ne_10m_coastline', 'ne_10m_coastline')
    shppath = coastpath + '.shp'
    prjpath = coastpath + '.prj'

    try:
        from osgeo import osr

        # From http://gis.stackexchange.com/questions/17341/
        prjText = open(prjpath, 'r').read()
        srs = osr.SpatialReference()
        if (srs.ImportFromWkt(prjText)):
            print("error importing .prj information from ", prjpath)
            return (None, None)
        inProjection = pyproj.Proj(srs.ExportToProj4())
    except ImportError:
        inProjection = pyproj.Proj('+proj=longlat +ellps=WGS84 +no_defs')

    sf = shapefile.Reader(shppath)
    world = np.vstack(
        [shp.points for (rec, shp) in zip(sf.records(), sf.shapes()) if rec[1] <= 1.0]).T

    return (world, inProjection)


def shape2pixels(inproj, outproj, shape, Ahat, that):
    import pyproj
    shape = pyproj.transform(inproj, outproj, *shape)

    #countries = [c[3] for c in sf.records()]
    #mongolia = np.array(sf.shape(countries.index('Mongolia')).points).T
    #mongolia = pyproj.transform(inProjection, outproj, *mongolia)

    xout, yout = np.dot(Ahat, shape) + that

    return np.array([xout, yout])


def image_show(x,
               y,
               xout,
               yout,
               imname="TheSteppe.jpg",
               description="",
               shape=None,
               inproj=None,
               outproj=None,
               Ahat=None,
               that=None,
               **shapeargs):
    """Load and show an image with control points and estimates.

    Given control points in vectors x and y containing pixels, as well as
    estimates obtained (using some projection), plot both values so they can be
    visually compared.

    """
    import pylab as plt
    plt.ion()
    try:
        im = plt.imread(imname)
    except IOError:
        print("Couldn't load {}, can't display image!".format(imname))
        return

    fig = plt.figure()
    ax = fig.add_subplot(111)

    ax.imshow(im, interpolation='bicubic')
    imaxis = ax.axis()

    def annot_helper(x, y, c='k', **kwargs):
        ax.annotate(
            "%g,%g" % (x, y),
            xy=(x, y),
            xytext=(x + 30, y + 30),
            size=15,
            arrowprops=dict(facecolor=c, width=1.0, frac=0.5),
            color=c,
            **kwargs)

    [annot_helper(xi, yi, 'g') for xi, yi in zip(x, y)]
    [annot_helper(xi, yi, 'r') for xi, yi in zip(xout, yout)]

    plt.title(description + " (Green: control points, red: fit points)")

    if shape is not None:
        (shapex, shapey) = shape2pixels(inproj, outproj, shape, Ahat, that)
        plt.plot(
            shapex, -shapey, marker='.', markersize=1.0, linestyle='none', hold=True, **shapeargs)

    ax.axis(imaxis)
    plt.show()

    return ax


def searchsolution2xy(lon,
                      lat,
                      x,
                      y,
                      proj,
                      vec2dictfunc,
                      solvec,
                      plot=True,
                      description="",
                      shape=None,
                      inproj=None):
    xy = np.vstack([x, y])
    solutionvec = solvec[0]
    solutionerr = solvec[1]
    p = Proj(proj=proj, **vec2dictfunc(solutionvec))
    xout, yout = p(lon, lat)
    ((xout, yout), _, Ahat, that) = remove_affine(xy, np.vstack([xout, yout]))

    if plot:
        descriptor = "%s%s projection (fit error %.3f)" % (description, proj, solutionerr)
        ax = image_show(
            x,
            -y,
            xout,
            -yout,
            description=descriptor,
            shape=shape,
            inproj=inproj,
            outproj=p,
            Ahat=Ahat,
            that=that)

    return (xout, yout, p, Ahat, that, ax)


if __name__ == "__main__":
    (shape, shapeproj) = loadshapefile()
    (lon, lat, x, y) = loaddata()

    fit_description = ''

    # This is how you fit 4 parameters
    fit_proj = 'aea'
    fit_v2dfunc = make_vector2dictfunc("lon_0,lat_0,lat_1,lat_2")
    fit_init = [80.0, 50, 40, 60]
    searchsolution2xy(
        lon,
        lat,
        x,
        y,
        fit_proj,
        fit_v2dfunc,
        search(lon, lat, x, y, fit_proj, fit_v2dfunc, fit_init),
        description=fit_description,
        shape=shape,
        inproj=shapeproj)

    # I believe this is the projection though: 1-parameter Winkel Triple.
    fit_proj = 'wintri'
    fit_v2dfunc = make_vector2dictfunc("lon_0")
    fit_init = [47.0]
    xout, yout, p, Ahat, that, ax = searchsolution2xy(
        lon,
        lat,
        x,
        y,
        fit_proj,
        fit_v2dfunc,
        search(lon, lat, x, y, fit_proj, fit_v2dfunc, fit_init),
        description=fit_description,
        shape=shape,
        inproj=shapeproj)
    print(p.srs)

    recoveredPixels = Ahat @ p(lon, lat) + that
    origPixels = np.vstack([x, y])
    absoluteError = origPixels - recoveredPixels
    relativeError = absoluteError / origPixels

    pixToLonlat = lambda x, y: p(*np.linalg.solve(Ahat, np.vstack([x, y]) - that), inverse=True)
    (top_left_lon, top_left_lat) = pixToLonlat(0, 0)
    import pylab as plt
    im = plt.imread('TheSteppe.jpg')
    height, width = im.shape[:2]
    (bottom_right_lon, bottom_right_lat) = pixToLonlat(width, -height)
    cmd = ("gdal_translate -of GTiff -a_ullr {top_left_lon} {top_left_lat} {bottom_right_lon}" +
           " {bottom_right_lat} -a_srs SR-ORG:7291 TheSteppe.jpg output.tif").format(
               top_left_lon=top_left_lon[0],
               top_left_lat=top_left_lat[0],
               bottom_right_lon=bottom_right_lon[0],
               bottom_right_lat=bottom_right_lat[0])
    """
    gdal_translate -of GTiff -a_ullr -3.5083634007813402 70.372117747633 131.7449661509387 3.5400212381456004 -a_srs SR-ORG:7291 TheSteppe.jpg output.tif
    """
    # This probably won't work because the Winkel Triple projection isn't widely supported.
    # Fine. We can do interpolations ourselves!
    xs, ys = np.meshgrid(np.arange(width), -np.arange(height))
    origLon, origLat = pixToLonlat(xs.ravel(), ys.ravel())
    vecToBounds = lambda x: np.array([np.min(x), np.max(x)])
    boundLon = vecToBounds(origLon)
    boundLat = vecToBounds(origLat)
    degPerPix = 0.05
    outLon, outLat = np.meshgrid(
        np.arange(boundLon[0] - 0.5, boundLon[1] + 0.5, degPerPix),
        np.arange(boundLat[0] - 0.5, boundLat[1] + 0.5, degPerPix))

    from scipy.interpolate import griddata
    res = np.dstack([
        griddata(
            np.vstack([origLon, origLat]).T,
            im[:, :, i].ravel(),
            np.vstack([outLon.ravel(), outLat.ravel()]).T,
            method='nearest').reshape(outLon.shape) for i in range(3)
    ])

    plt.imsave(fname='out.png', arr=res[::-1, :, :])

    earthRadius = 6378137
    mPerDeg = np.pi / 180 * earthRadius
    print(("out.png saved, equirectangular (Plate Carree) projection, with corners: " +
           "top_left_lon={top_left_lon} top_left_lat={top_left_lat} " +
           "bottom_right_lon={bottom_right_lon} bottom_right_lat={bottom_right_lat} deg").format(
               top_left_lon=outLon[0, 0],
               top_left_lat=outLat[-1, -1],
               bottom_right_lon=outLon[-1, -1],
               bottom_right_lat=outLat[0, 0]))
    cmd = ("gdal_translate -of GTiff -a_ullr {top_left_lon} {top_left_lat} {bottom_right_lon}" +
           " {bottom_right_lat} -a_srs EPSG:32662 out.png output.tif").format(
               top_left_lon=outLon[0, 0] * mPerDeg,
               top_left_lat=outLat[-1, -1] * mPerDeg,
               bottom_right_lon=outLon[-1, -1] * mPerDeg,
               bottom_right_lat=outLat[0, 0] * mPerDeg)
    print(cmd)